{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1) What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?\n",
        "**Ans:** TensorFlow 2.0, released in September 2019, introduced significant enhancements over TensorFlow 1.x to improve usability and performance. Key differences include:\n",
        "\n",
        "1. **Eager Execution by Default**: Operations execute immediately, simplifying model development.\n",
        "\n",
        "2. **Unified High-Level API with Keras**: Integration of Keras provides a consistent interface for building and training models.\n",
        "\n",
        "3. **Streamlined APIs**: Removal of redundant and deprecated APIs results in a cleaner codebase.\n",
        "\n",
        "4. **`tf.function` for Graph Execution**: Allows automatic conversion of Python functions into TensorFlow graphs, combining ease of use with performance benefits.\n",
        "\n",
        "5. **Improved Variable Management**: Adoption of `ResourceVariables` enhances concurrency semantics.\n",
        "\n",
        "6. **Simplified TensorShape API**: Tensor shapes are more intuitive, holding integers directly.\n",
        "\n",
        "7. **Updated Tensor Equality Mechanics**: The `==` operator now checks for value equality, aligning with standard Python behavior.\n",
        "\n",
        "# 2) How do you install TensorFlow 2.0?\n",
        "**Ans:** To install TensorFlow 2.0, follow these steps:\n",
        "\n",
        "1. **Install TensorFlow 2.0**:\n",
        "   - Use `pip` to install TensorFlow:\n",
        "     ```bash\n",
        "     pip install tensorflow==2.0.0\n",
        "     ```\n",
        "   - For GPU support, ensure your system meets the necessary requirements and install the GPU version:\n",
        "     ```bash\n",
        "     pip install tensorflow-gpu==2.0.0\n",
        "     ```\n",
        "     *Note*: Verify compatibility of your GPU, CUDA, and cuDNN versions with TensorFlow 2.0.\n",
        "\n",
        "2. **Verify the Installation**:\n",
        "   - Open a Python interpreter and execute:\n",
        "     ```python\n",
        "     import tensorflow as tf\n",
        "     print(tf.__version__)\n",
        "     ```\n",
        "   - This should output `2.0.0`, confirming a successful installation.\n",
        "\n",
        "# 3) What is the primary function of the tf.function in TensorFlow 2.0?\n",
        "**Ans:** In TensorFlow 2.0, the `tf.function` decorator transforms Python functions into TensorFlow computation graphs. This conversion enhances performance by enabling optimizations and efficient execution across various platforms, including GPUs and TPUs. Additionally, `tf.function` allows for a more Pythonic coding style by interpreting common Python constructs, such as loops and conditionals, into their TensorFlow graph equivalents.\n",
        "\n",
        "# 4) What is the purpose of the Model class in TensorFlow 2.0?\n",
        "**Ans:** In TensorFlow 2.0, the `tf.keras.Model` class is essential for building and managing machine learning models. Its primary functions include:\n",
        "\n",
        "- **Defining Model Architecture**: It allows for the creation of complex neural network structures by organizing layers into a cohesive model.\n",
        "\n",
        "- **Training and Evaluation**: The class provides methods like `compile()`, `fit()`, and `evaluate()` to streamline the training and assessment of models.\n",
        "\n",
        "- **Saving and Loading Models**: It facilitates model serialization, enabling easy saving and loading of model configurations and weights.\n",
        "\n",
        "# 5) How do you create a neural network using TensorFlow 2.0?\n",
        "**Ans:** Creating a neural network in TensorFlow 2.0 is streamlined with the `tf.keras` API. Here's a concise guide to building a simple feedforward neural network:\n",
        "\n",
        "1. **Import Necessary Libraries**:\n",
        "\n",
        "   ```python\n",
        "   import tensorflow as tf\n",
        "   from tensorflow.keras import layers, models\n",
        "   ```\n",
        "\n",
        "2. **Define the Model Architecture**:\n",
        "\n",
        "   Utilize the Sequential API to stack layers:\n",
        "\n",
        "   ```python\n",
        "   model = models.Sequential([\n",
        "       layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "       layers.Dense(64, activation='relu'),\n",
        "       layers.Dense(num_classes, activation='softmax')\n",
        "   ])\n",
        "   ```\n",
        "\n",
        "   - Replace `input_dim` with the number of features in your input data.\n",
        "   - Adjust `num_classes` to match the number of output classes for classification tasks.\n",
        "\n",
        "# 6) What is the importance of Tensor Space in TensorFlow?\n",
        "**Ans:** The concept of **tensor space** in TensorFlow refers to the multi-dimensional space where tensors (multi-dimensional arrays) reside and are manipulated. Its importance lies in the following:\n",
        "\n",
        "1. **Data Representation**:\n",
        "   - Tensors represent data in a structured way, allowing for seamless handling of scalars (0D), vectors (1D), matrices (2D), and higher-dimensional arrays (e.g., 3D tensors for images or 4D tensors for batches of images).\n",
        "\n",
        "2. **Mathematical Operations**:\n",
        "   - Tensor space provides a foundation for performing mathematical operations like matrix multiplication, convolution, and gradients, essential in machine learning and deep learning.\n",
        "\n",
        "3. **Dimensionality and Transformation**:\n",
        "   - The tensor space enables transformations like reshaping, slicing, and broadcasting, which are crucial for preparing and feeding data into models.\n",
        "\n",
        "4. **Optimized Execution**:\n",
        "   - TensorFlow's optimized computation graph utilizes tensor spaces to execute operations efficiently on CPUs, GPUs, or TPUs.\n",
        "\n",
        "5. **Scalability**:\n",
        "   - Tensor spaces allow TensorFlow to handle small datasets and large-scale distributed data for complex models like neural networks.\n",
        "\n",
        "# 7) How can TensorBoard be integrated with TensorFlow 2.0?\n",
        "**Ans:** Integrating TensorBoard with TensorFlow 2.0 enhances the visualization and tracking of your machine learning models. Here's how to set it up:\n",
        "\n",
        "1. **Import Necessary Libraries**:\n",
        "\n",
        "   ```python\n",
        "   import tensorflow as tf\n",
        "   from tensorflow.keras.callbacks import TensorBoard\n",
        "   import datetime\n",
        "   ```\n",
        "\n",
        "2. **Prepare Your Model**:\n",
        "\n",
        "   Define and compile your Keras model as usual.\n",
        "\n",
        "   ```python\n",
        "   model = tf.keras.models.Sequential([\n",
        "       tf.keras.layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "       tf.keras.layers.Dense(64, activation='relu'),\n",
        "       tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "   ])\n",
        "\n",
        "   model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "   ```\n",
        "\n",
        "3. **Set Up TensorBoard Callback**:\n",
        "\n",
        "   Create a log directory with a timestamp to store TensorBoard logs.\n",
        "\n",
        "   ```python\n",
        "   log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "   tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "   ```\n",
        "\n",
        "4. **Train the Model with TensorBoard Callback**:\n",
        "\n",
        "   Include the `tensorboard_callback` in the `callbacks` parameter of the `fit` method.\n",
        "\n",
        "   ```python\n",
        "   model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val), callbacks=[tensorboard_callback])\n",
        "   ```\n",
        "\n",
        "5. **Launch TensorBoard**:\n",
        "\n",
        "   After training, start TensorBoard from the command line:\n",
        "\n",
        "   ```bash\n",
        "   tensorboard --logdir=logs/fit\n",
        "   ```\n",
        "\n",
        "   Then, navigate to `http://localhost:6006/` in your browser to visualize the training process.\n",
        "\n",
        "# 8) What is the purpose of TensorFlow Playground?\n",
        "**Ans:**\n",
        "TensorFlow Playground is an interactive web application designed to help users understand the fundamentals of neural networks. It allows users to visualize and experiment with small neural networks directly in their browsers, providing an intuitive grasp of how these models learn and make predictions.\n",
        "# 9) What is Netron, and how is it useful for deep learning models?\n",
        "**Ans:** Netron is an open-source visualizer for deep learning and machine learning models. It supports various model formats, including ONNX, TensorFlow, Keras, Caffe, and PyTorch. Netron provides a user-friendly interface to explore model architectures, inspect layers, and understand data flow within the network.\n",
        "\n",
        "**Usefulness in Deep Learning:**\n",
        "\n",
        "- **Model Inspection**: Netron allows developers to verify the architecture of their models, ensuring that layers are correctly configured and connected.\n",
        "\n",
        "- **Debugging**: By visualizing the model, users can identify structural issues or discrepancies that may affect performance.\n",
        "\n",
        "- **Documentation and Sharing**: Visual representations of models can be useful for presentations, documentation, and collaborative work, facilitating better communication among team members.\n",
        "\n",
        "# 10) What is the difference between TensorFlow and PyTorch?\n",
        "**Ans:** TensorFlow and PyTorch are two leading open-source deep learning frameworks, each with distinct characteristics that cater to different user preferences and project requirements.\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "- **Computation Graphs**:\n",
        "  - *TensorFlow*: Employs static computation graphs, where the model architecture is defined and then executed. This approach can lead to optimizations in deployment but may require more effort during the development phase to modify the model.\n",
        "  - *PyTorch*: Utilizes dynamic computation graphs, allowing for real-time modifications during execution. This flexibility facilitates easier debugging and experimentation.\n",
        "\n",
        "- **Ease of Use**:\n",
        "  - *TensorFlow*: Offers a comprehensive ecosystem with extensive tools and libraries, which can present a steeper learning curve for newcomers.\n",
        "  - *PyTorch*: Known for its \"pythonic\" design, it integrates seamlessly with Python, making it more intuitive and accessible, especially for researchers and beginners.\n",
        "\n",
        "- **Deployment and Production**:\n",
        "  - *TensorFlow*: Provides robust support for deploying models across various platforms, including mobile and web, with tools like TensorFlow Serving and TensorFlow Lite.\n",
        "  - *PyTorch*: While traditionally favored in research settings, PyTorch has made significant strides in deployment capabilities with tools such as TorchServe.\n",
        "\n",
        "- **Community and Industry Adoption**:\n",
        "  - *TensorFlow*: Backed by Google, it has a vast community and is widely adopted in industry applications.\n",
        "  - *PyTorch*: Supported by Facebook's AI Research lab, it has seen rapid growth in the research community and is increasingly being adopted in industry settings.\n",
        "\n",
        "- **Performance and Scalability**:\n",
        "  - Both frameworks offer competitive performance. TensorFlow's static graphs can be optimized for various hardware configurations, potentially providing an edge in large-scale deployments. PyTorch's dynamic nature offers flexibility, which can be advantageous in research and development phases.\n",
        "\n",
        "# 11) How do you install PyTorch?\n",
        "**Ans:**\n",
        "- **Operating System:** Identify whether you're using Windows, macOS, or Linux.\n",
        "\n",
        "- **Python Version:** Ensure Python is installed. You can check by running `python --version` or `python3 --version` in your command line.\n",
        "\n",
        "- **Package Manager:** Decide between using `pip` or `Anaconda (conda)` for installation.\n",
        "\n",
        "- **CUDA Support:** If you have an NVIDIA GPU and wish to utilize it, determine the CUDA version installed on your system. If you're unsure or don't require GPU support, you can opt for the CPU-only version.\n",
        "\n",
        "# 12) What is the basic structure of a PyTorch neural network?\n",
        "**Ans:** In PyTorch, constructing a neural network involves defining a class that inherits from `torch.nn.Module`. This class encapsulates the layers and operations of the network.\n",
        "\n",
        "**Basic Structure of a PyTorch Neural Network:**\n",
        "\n",
        "1. **Import Necessary Modules**:\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   import torch.nn as nn\n",
        "   ```\n",
        "\n",
        "2. **Define the Neural Network Class**:\n",
        "\n",
        "   ```python\n",
        "   class MyNeuralNetwork(nn.Module):\n",
        "       def __init__(self):\n",
        "           super(MyNeuralNetwork, self).__init__()\n",
        "           # Define layers here\n",
        "           self.layer1 = nn.Linear(in_features, out_features)\n",
        "           self.layer2 = nn.ReLU()\n",
        "           self.layer3 = nn.Linear(out_features, final_output_features)\n",
        "       \n",
        "       def forward(self, x):\n",
        "           # Define forward pass\n",
        "           x = self.layer1(x)\n",
        "           x = self.layer2(x)\n",
        "           x = self.layer3(x)\n",
        "           return x\n",
        "   ```\n",
        "\n",
        "   - **`__init__` Method**: This constructor initializes the layers of the network. Each layer is defined as an attribute of the class.\n",
        "\n",
        "   - **`forward` Method**: This method defines the forward pass of the network, specifying how data flows through the layers.\n",
        "\n",
        "# 13) What is the significance of tensors in PyTorch?\n",
        "**Ans:** The significance of tensors in PyTorch includes:\n",
        "\n",
        "- **Data Representation:** Tensors serve as the primary means of representing data, including inputs, outputs, and model parameters.\n",
        "\n",
        "- **Computation:** They support a wide range of mathematical operations, such as addition, multiplication, and more complex functions, enabling the implementation of various algorithms.\n",
        "\n",
        "- **Interoperability:** Tensors facilitate seamless integration with other libraries and frameworks, enhancing the flexibility and scalability of machine learning workflows.\n",
        "\n",
        "# 14) What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n",
        "**Ans:** In PyTorch, the distinction between `torch.Tensor` and `torch.cuda.Tensor` pertains to the device on which the tensor resides:\n",
        "\n",
        "- **`torch.Tensor`**: This is the default tensor type in PyTorch, which resides on the CPU. Operations performed on these tensors utilize the CPU.\n",
        "\n",
        "- **`torch.cuda.Tensor`**: This refers to tensors that are allocated on a CUDA-enabled GPU. Operations on these tensors leverage GPU acceleration, significantly enhancing computational performance for tasks like training deep learning models.\n",
        "\n",
        "# 15) What is the purpose of the torch.optim module in PyTorch?\n",
        "**Ans:** In PyTorch, the `torch.optim` module provides a suite of optimization algorithms essential for training neural networks. These algorithms adjust model parameters to minimize the loss function, thereby enhancing the model's performance.\n",
        "\n",
        "# 16) What are some common activation functions used in neural networks?\n",
        "**Ans:** In neural networks, activation functions introduce non-linearity, enabling the network to model complex patterns. Common activation functions include:\n",
        "\n",
        "- **Sigmoid**\n",
        "\n",
        "- **Tanh (Hyperbolic Tangent)**\n",
        "\n",
        "- **ReLU (Rectified Linear Unit)**\n",
        "\n",
        "- **Leaky ReLU**\n",
        "\n",
        "- **Softmax**\n",
        "# 17) What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n",
        "**Ans:** In PyTorch, both `torch.nn.Module` and `torch.nn.Sequential` are used to define neural network architectures, but they serve different purposes and offer varying levels of flexibility.\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "- **Complexity**: `nn.Module` is ideal for complex models with intricate architectures, while `nn.Sequential` is best for simple, linear stacks of layers.\n",
        "\n",
        "- **Control**: `nn.Module` offers full control over the forward pass, enabling custom operations and connections. In contrast, `nn.Sequential` automatically defines the forward pass by chaining the modules in the order they are added.\n",
        "\n",
        "- **Use Cases**: Use `nn.Module` when the model requires custom behavior or non-sequential connections. Opt for `nn.Sequential` when the model consists of a straightforward sequence of layers.\n",
        "\n",
        "# 18) How can you monitor training progress in TensorFlow 2.0?\n",
        "**Ans:** Monitoring training progress in TensorFlow 2.0 is essential for evaluating model performance and ensuring effective training. Two primary methods for monitoring are:\n",
        "1. Using TensorBoard for Visualization\n",
        "2. Using Progress Bars for Real-Time Updates:\n",
        "    - Using `tf.keras.utils.Progbar`\n",
        "    - Using `tqdm` for Enhanced Progress Bars\n",
        "\n",
        "# 19) How does the Keras API fit into TensorFlow 2.0?\n",
        "**Ans:** In TensorFlow 2.0, the Keras API serves as the primary high-level interface for building and training deep learning models. It offers a user-friendly, modular, and extensible framework that streamlines the development process, making it accessible for both beginners and experienced practitioners.\n",
        "\n",
        "# 20) What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n",
        "**Ans:** TensorFlow 2.0 offers a robust framework for implementing various deep learning projects. Here are some examples:\n",
        "- Text Generation\n",
        "- Music Generation\n",
        "- Speech Recognition\n",
        "- Time Series Forecasting\n",
        "\n",
        "# 21) What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "**Ans:** Utilizing pre-trained models in deep learning frameworks like TensorFlow and PyTorch offers several significant advantages:\n",
        "\n",
        "**1. Reduced Training Time:**\n",
        "Pre-trained models have already learned to extract essential features from data, allowing you to fine-tune them for your specific task rather than training from scratch. This approach significantly decreases the time and computational resources required for training.\n",
        "\n",
        "**2. Improved Performance with Limited Data:**\n",
        "When working with small datasets, pre-trained models can achieve higher accuracy by leveraging knowledge from large-scale datasets they were initially trained on. This transfer learning capability enhances performance in scenarios where data is scarce.\n",
        "\n",
        "**3. Access to Advanced Architectures:**\n",
        "Pre-trained models often incorporate state-of-the-art architectures and techniques, providing a solid foundation for your projects. This access enables you to build upon cutting-edge research without the need to develop complex models from the ground up.\n",
        "\n"
      ],
      "metadata": {
        "id": "KI1VknNXcg_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical"
      ],
      "metadata": {
        "id": "edJ8pub-tLRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) How do you install and verify that TensorFlow 2.0 was installed successfully?"
      ],
      "metadata": {
        "id": "ZjOE3abStPhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "5oY6g-t_tUIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "LlvNkdIwtrie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) How can you define a simple function in TensorFlow 2.0 to perform addition?"
      ],
      "metadata": {
        "id": "TtsEMd8rtwgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def add(a, b):\n",
        "    return tf.add(a, b)"
      ],
      "metadata": {
        "id": "EusYifcFt8bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?"
      ],
      "metadata": {
        "id": "IBvqMam-uI85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(units=64, activation='relu', input_shape=(10,)),  # Hidden layer with 64 neurons\n",
        "    Dense(units=1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DCp1by8ouOav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) How can you visualize the training progress using TensorFlow and Matplotlib?"
      ],
      "metadata": {
        "id": "XaQ8_fB7ubdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define and compile your model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and capture the history\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "HciAzR80uhIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1LD7eZYNwFiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YzglwO6vwIMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) How do you install PyTorch and verify the PyTorch installation?"
      ],
      "metadata": {
        "id": "ToGtSL_QwLzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "KMMVw-tnwPHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "ka3sqjr7wW_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) How do you create a simple neural network in PyTorch?"
      ],
      "metadata": {
        "id": "mRHk53DHwagk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),  # Input layer to hidden layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),    # Hidden layer to hidden layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)      # Hidden layer to output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "ONwch47mwd_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) How do you define a loss function and optimizer in PyTorch?\n"
      ],
      "metadata": {
        "id": "fHoIM0hXwrcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "9Ggv4JkOwu-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) How do you implement a custom loss function in PyTorch?"
      ],
      "metadata": {
        "id": "Y6WzgTdzxDT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Implement your custom loss computation here\n",
        "        loss = torch.mean((predictions - targets) ** 2)  # Example: Mean Squared Error\n",
        "        return loss"
      ],
      "metadata": {
        "id": "PUNVkiWFxGB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9) How do you save and load a TensorFlow model?"
      ],
      "metadata": {
        "id": "zkhV4FOExWgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model\n",
        "model.save('path_to_my_model.keras')\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the entire model\n",
        "model = keras.models.load_model('path_to_my_model.keras')\n"
      ],
      "metadata": {
        "id": "08cPuArzxm4o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}