{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ba4501990064af099751cffef002de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cb27bee4b984c469d25de1f2cf6d352",
              "IPY_MODEL_f732b89e2de546d2bc7e95f8a68fcd26",
              "IPY_MODEL_e6a8fd127c6f4d3eac3596a46a84a038"
            ],
            "layout": "IPY_MODEL_fbf9976e4fee49f096e1c7c8b4dd6e86"
          }
        },
        "3cb27bee4b984c469d25de1f2cf6d352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a0a74887d349e594ab69d57aa31ad0",
            "placeholder": "​",
            "style": "IPY_MODEL_a2a75ff077904aa18614cafa4c98586d",
            "value": "config.json: 100%"
          }
        },
        "f732b89e2de546d2bc7e95f8a68fcd26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf29254081c94c4f9fa2aa4ffccb6164",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_442dd1814fa549c2a023e1f720d4820a",
            "value": 665
          }
        },
        "e6a8fd127c6f4d3eac3596a46a84a038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59db2866d6b44a4b726d7c220901b0f",
            "placeholder": "​",
            "style": "IPY_MODEL_a3fedbc566794e599ebf1ead0053239b",
            "value": " 665/665 [00:00&lt;00:00, 37.4kB/s]"
          }
        },
        "fbf9976e4fee49f096e1c7c8b4dd6e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a0a74887d349e594ab69d57aa31ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a75ff077904aa18614cafa4c98586d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf29254081c94c4f9fa2aa4ffccb6164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442dd1814fa549c2a023e1f720d4820a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b59db2866d6b44a4b726d7c220901b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3fedbc566794e599ebf1ead0053239b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "139d167d4b5249198d090efbc0a6c78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac9390c53974f61990c515760e3f725",
              "IPY_MODEL_cfbd5868c5d14b1683a6507813d74d42",
              "IPY_MODEL_31072a56d8274af693a25014fce381d0"
            ],
            "layout": "IPY_MODEL_a3dddb26066047a0b5d24c706d581d41"
          }
        },
        "5ac9390c53974f61990c515760e3f725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a150c4165c4c41e29195205b9cc246f6",
            "placeholder": "​",
            "style": "IPY_MODEL_158bd2f13b4f433dafe6642ae0b0e165",
            "value": "model.safetensors: 100%"
          }
        },
        "cfbd5868c5d14b1683a6507813d74d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff0a7eb929046b795921cc935cf4ea3",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e7f23d24844424d87c6213011a988af",
            "value": 548105171
          }
        },
        "31072a56d8274af693a25014fce381d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465c6d0c9ce047c2ab35cb2b731a9d41",
            "placeholder": "​",
            "style": "IPY_MODEL_6f853a5c47614ca5953b9752737d7bc0",
            "value": " 548M/548M [00:07&lt;00:00, 129MB/s]"
          }
        },
        "a3dddb26066047a0b5d24c706d581d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a150c4165c4c41e29195205b9cc246f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158bd2f13b4f433dafe6642ae0b0e165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bff0a7eb929046b795921cc935cf4ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7f23d24844424d87c6213011a988af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "465c6d0c9ce047c2ab35cb2b731a9d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f853a5c47614ca5953b9752737d7bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140e4b8633704bc1bd9c536f2b6cd4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55c05fe7be16499c8c43ac05e71d73d6",
              "IPY_MODEL_5ec61bc0da0d4e6998ef8fbfafdb9a87",
              "IPY_MODEL_fec7c11f573a4a22b252962e03eaf79a"
            ],
            "layout": "IPY_MODEL_cc5508b9d47244278e71706fa8e9e4b5"
          }
        },
        "55c05fe7be16499c8c43ac05e71d73d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f20bba50ef449dd99ec6931680e33a7",
            "placeholder": "​",
            "style": "IPY_MODEL_19a5fa7b26f548c8951f0f42bad4b3cb",
            "value": "generation_config.json: 100%"
          }
        },
        "5ec61bc0da0d4e6998ef8fbfafdb9a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a08730326b4bc2918feb2207bc0662",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7bc809488054f31a21a03399f8ec095",
            "value": 124
          }
        },
        "fec7c11f573a4a22b252962e03eaf79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b277ae299ec34bec89d586c4348fe824",
            "placeholder": "​",
            "style": "IPY_MODEL_2daeff5b8f314acea06b1392590b5063",
            "value": " 124/124 [00:00&lt;00:00, 5.93kB/s]"
          }
        },
        "cc5508b9d47244278e71706fa8e9e4b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f20bba50ef449dd99ec6931680e33a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a5fa7b26f548c8951f0f42bad4b3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50a08730326b4bc2918feb2207bc0662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7bc809488054f31a21a03399f8ec095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b277ae299ec34bec89d586c4348fe824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2daeff5b8f314acea06b1392590b5063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61fc53a26ae047dd861265285bead44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20fc9917d9014851ba600db60564b39b",
              "IPY_MODEL_7a63d7f3f3b24f1f8826f7983d7413c6",
              "IPY_MODEL_55380c1709b3461ea9c66df50a12be54"
            ],
            "layout": "IPY_MODEL_a14d86c78df7450c8a17e9c694853c69"
          }
        },
        "20fc9917d9014851ba600db60564b39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ece2c2889e94314832c240569864bad",
            "placeholder": "​",
            "style": "IPY_MODEL_a965471315604bd8a8d3d819b74c507d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7a63d7f3f3b24f1f8826f7983d7413c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d69805b51f475da40384bdb605a60c",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_627faac3cd0944ccad5e7d0270ecd5ee",
            "value": 26
          }
        },
        "55380c1709b3461ea9c66df50a12be54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd1c6adf39a24aa89dfbb59db2259e44",
            "placeholder": "​",
            "style": "IPY_MODEL_192aaa4f0008479fbcabdfb03734e5fb",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.38kB/s]"
          }
        },
        "a14d86c78df7450c8a17e9c694853c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ece2c2889e94314832c240569864bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a965471315604bd8a8d3d819b74c507d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d69805b51f475da40384bdb605a60c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627faac3cd0944ccad5e7d0270ecd5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd1c6adf39a24aa89dfbb59db2259e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192aaa4f0008479fbcabdfb03734e5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e12a61cddc34071813c79d723d370aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab72e140b62c43159803bccffda22116",
              "IPY_MODEL_d88765d4bc5a4d14a1f938e7c8ca7941",
              "IPY_MODEL_c3ba7c9131bb46748710fc65f5ca42e4"
            ],
            "layout": "IPY_MODEL_758a56834f384ee49555ab95c615aa01"
          }
        },
        "ab72e140b62c43159803bccffda22116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294a39856aeb46cbbef1d360dc561a28",
            "placeholder": "​",
            "style": "IPY_MODEL_116e70f80eb84537b6d0335469b2d986",
            "value": "vocab.json: 100%"
          }
        },
        "d88765d4bc5a4d14a1f938e7c8ca7941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab493ee8f6d4f22a9817ffa133d8885",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef659fe1117842fbbf95785758f9e21d",
            "value": 1042301
          }
        },
        "c3ba7c9131bb46748710fc65f5ca42e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f548420a1f840e5a1dd2840d110fd16",
            "placeholder": "​",
            "style": "IPY_MODEL_65761d782fd54c49882a50f0c47c664d",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 7.43MB/s]"
          }
        },
        "758a56834f384ee49555ab95c615aa01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294a39856aeb46cbbef1d360dc561a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116e70f80eb84537b6d0335469b2d986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab493ee8f6d4f22a9817ffa133d8885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef659fe1117842fbbf95785758f9e21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f548420a1f840e5a1dd2840d110fd16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65761d782fd54c49882a50f0c47c664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a625525cfd734820a98ae15569dab0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56aa4009fc8542f5a093e554b84ff4de",
              "IPY_MODEL_626ea821438048c385aa67a6a0c20c89",
              "IPY_MODEL_647527b05ecc42ffb869b182ba464f51"
            ],
            "layout": "IPY_MODEL_a945e873ee5e4c9281d1858eeefcd509"
          }
        },
        "56aa4009fc8542f5a093e554b84ff4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e6988e99c9425ca6d1d842b6a16eba",
            "placeholder": "​",
            "style": "IPY_MODEL_6b4f595fde514badb859226110c6f2c7",
            "value": "merges.txt: 100%"
          }
        },
        "626ea821438048c385aa67a6a0c20c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd4158715f5f48bc80d6c5ed93875868",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cc49c0d7373488e9b774a44cda4a35b",
            "value": 456318
          }
        },
        "647527b05ecc42ffb869b182ba464f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40fb04d47e6c4d54b0f726a64708e851",
            "placeholder": "​",
            "style": "IPY_MODEL_1e7f75502bc34415ac61ca6be063bd23",
            "value": " 456k/456k [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "a945e873ee5e4c9281d1858eeefcd509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e6988e99c9425ca6d1d842b6a16eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4f595fde514badb859226110c6f2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd4158715f5f48bc80d6c5ed93875868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc49c0d7373488e9b774a44cda4a35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40fb04d47e6c4d54b0f726a64708e851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7f75502bc34415ac61ca6be063bd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66108bdd54704cb79ac14e7f329e9a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6913ce535924185bd8fc5c45db84434",
              "IPY_MODEL_fbfa4d6274364d6785dbed67445d5bfd",
              "IPY_MODEL_2281d388aa48486482a7c64948184418"
            ],
            "layout": "IPY_MODEL_1f37a97e74a44475a19076832961c740"
          }
        },
        "a6913ce535924185bd8fc5c45db84434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c36e5582f3446cb8de4c41e1f5b400",
            "placeholder": "​",
            "style": "IPY_MODEL_029158e74b1c4ac5b2402a9d569ca778",
            "value": "tokenizer.json: 100%"
          }
        },
        "fbfa4d6274364d6785dbed67445d5bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19b232d5aa4b4d9499aede19808813ff",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4b5f2f8eb274a828e7628a3ee9f75e5",
            "value": 1355256
          }
        },
        "2281d388aa48486482a7c64948184418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ddb2cbc1eb49cabead02146c5574ad",
            "placeholder": "​",
            "style": "IPY_MODEL_ee46bdfce576444e8b44367d059ffbf2",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 17.7MB/s]"
          }
        },
        "1f37a97e74a44475a19076832961c740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c36e5582f3446cb8de4c41e1f5b400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029158e74b1c4ac5b2402a9d569ca778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19b232d5aa4b4d9499aede19808813ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b5f2f8eb274a828e7628a3ee9f75e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8ddb2cbc1eb49cabead02146c5574ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee46bdfce576444e8b44367d059ffbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1) What is BERT and how does it work?\n",
        "**Ans:** **BERT (Bidirectional Encoder Representations from Transformers)** is a pre-trained deep learning model for natural language processing (NLP) tasks. It was developed by Google and is designed to understand the context of words in a sentence by looking at both the words before and after it, making it bidirectional (instead of just looking at the previous words, as many models did before).\n",
        "\n",
        "### How BERT Works:\n",
        "\n",
        "1. **Transformer Architecture:**\n",
        "   - BERT is based on the **Transformer** architecture, which uses attention mechanisms to process input data. The Transformer model doesn't rely on sequence order, so it can process all words in parallel rather than one at a time like older models.\n",
        "   \n",
        "2. **Bidirectional Context:**\n",
        "   - Unlike traditional models like RNNs or LSTMs that process text in one direction (left-to-right or right-to-left), BERT looks at the full sentence at once, considering the context from both directions.\n",
        "   \n",
        "3. **Masked Language Model (MLM):**\n",
        "   - During pre-training, BERT uses a technique called **masked language modeling**. It randomly masks some words in a sentence and tries to predict them based on the surrounding context. This helps BERT learn the relationship between words and the context they appear in.\n",
        "\n",
        "4. **Next Sentence Prediction (NSP):**\n",
        "   - BERT is also trained on the task of **next sentence prediction**. It learns to predict whether a given sentence logically follows another, helping it understand sentence relationships.\n",
        "\n",
        "# 2) What are the main advantages of using the attention mechanism in neural networks?\n",
        "**Ans:** The attention mechanism in neural networks offers several significant advantages:\n",
        "\n",
        "1. **Focus on Relevant Information**:  \n",
        "   Attention allows the model to dynamically focus on the most important parts of the input data while ignoring irrelevant information, improving performance on tasks like machine translation and image captioning.\n",
        "\n",
        "2. **Improved Long-Range Dependencies**:  \n",
        "   Attention mechanisms help capture relationships between distant elements in the input sequence, overcoming limitations of models like vanilla RNNs or LSTMs in handling long-range dependencies.\n",
        "\n",
        "3. **Parallelization**:  \n",
        "   Unlike RNNs, attention mechanisms, especially in transformers, enable processing all input elements simultaneously, leading to faster training and inference.\n",
        "\n",
        "4. **Interpretability**:  \n",
        "   Attention weights provide insights into which parts of the input the model focused on during decision-making, enhancing interpretability and trust in the model.\n",
        "\n",
        "5. **Versatility Across Modalities**:  \n",
        "   Attention is applicable to various data types—text, images, audio, and even multimodal data—making it a versatile tool for diverse tasks.\n",
        "\n",
        "6. **Enhanced Representations**:  \n",
        "   By considering the global context, attention mechanisms create richer and more nuanced representations of the data, improving model accuracy.\n",
        "\n",
        "7. **Scalability**:  \n",
        "   With the advent of transformer models, attention mechanisms scale effectively with larger datasets and higher model complexity, as seen in models like GPT and BERT.\n",
        "\n",
        "# 3) How does the self-attention mechanism differ from traditional attention mechanisms?\n",
        "**Ans:** The **self-attention mechanism** differs from traditional attention mechanisms in several key aspects:\n",
        "\n",
        "1. **Scope of Application**:\n",
        "   - **Traditional Attention**:\n",
        "     - Operates between two distinct sequences, such as the encoder and decoder in sequence-to-sequence models.\n",
        "     - Aligns elements from the input sequence to the output sequence, facilitating tasks like machine translation.\n",
        "   - **Self-Attention**:\n",
        "     - Operates within a single sequence, allowing each element to attend to all other elements in the same sequence.\n",
        "     - Captures intra-sequence dependencies, which is crucial for understanding context within the sequence.\n",
        "\n",
        "2. **Functionality**:\n",
        "   - **Traditional Attention**:\n",
        "     - Enhances the model's focus on relevant parts of the input when generating each part of the output.\n",
        "     - Improves performance in tasks where alignment between input and output sequences is essential.\n",
        "   - **Self-Attention**:\n",
        "     - Enables the model to weigh the importance of different elements within the same sequence.\n",
        "     - Allows for the capture of long-range dependencies without relying on recurrent architectures.\n",
        "\n",
        "3. **Architectural Integration**:\n",
        "   - **Traditional Attention**:\n",
        "     - Often used in conjunction with recurrent neural networks (RNNs) to improve their performance by focusing on relevant parts of the input sequence.\n",
        "   - **Self-Attention**:\n",
        "     - Forms the backbone of Transformer architectures, replacing the need for recurrence and enabling parallelization.\n",
        "     - Leads to more efficient training and inference, especially for large-scale models.\n",
        "\n",
        "4. **Computational Complexity**:\n",
        "   - **Traditional Attention**:\n",
        "     - Computationally intensive due to the sequential nature of RNNs, limiting parallelization.\n",
        "   - **Self-Attention**:\n",
        "     - Allows for parallel computation, reducing training time and enabling the handling of larger datasets.\n",
        "\n",
        "# 4) What is the role of the decoder in a Seq2Seq model?\n",
        "**Ans:** In a Sequence-to-Sequence (Seq2Seq) model, the **decoder** plays a crucial role in generating the output sequence based on the encoded representation of the input. Its primary functions include:\n",
        "\n",
        "1. **Generating the Output Sequence**:\n",
        "   - The decoder takes the context vector (also known as the thought vector) produced by the encoder and generates the output sequence. It operates in an autoregressive manner, producing one element of the output sequence at a time.\n",
        "\n",
        "2. **Utilizing Encoder's Context**:\n",
        "   - The decoder uses the hidden representation from the encoder to generate the output sequence.\n",
        "\n",
        "3. **Incorporating Attention Mechanism**:\n",
        "   - In models enhanced with attention mechanisms, the decoder can focus dynamically on the most relevant parts of the input sequence during the generation process. This approach boosts accuracy and provides valuable insights into the model’s decision-making process.\n",
        "\n",
        "# 5) What is the difference between GPT-2 and BERT models?\n",
        "**Ans:** GPT-2 and BERT are both influential language models based on the Transformer architecture, but they differ in several key aspects:\n",
        "\n",
        "**1. Model Architecture:**\n",
        "- **GPT-2 (Generative Pre-trained Transformer 2):**\n",
        "  - Employs a *decoder-only* Transformer architecture.\n",
        "  - Designed primarily for text generation tasks.\n",
        "- **BERT (Bidirectional Encoder Representations from Transformers):**\n",
        "  - Utilizes an *encoder-only* Transformer architecture.\n",
        "  - Aimed at understanding and processing language, excelling in tasks like text classification and question answering.\n",
        "\n",
        "**2. Training Objectives:**\n",
        "- **GPT-2:**\n",
        "  - Trained using a *causal language modeling* objective, predicting the next word in a sequence based on preceding words.\n",
        "  - Processes text in a unidirectional (left-to-right) manner.\n",
        "- **BERT:**\n",
        "  - Trained with a *masked language modeling* (MLM) objective, where random words in a sentence are masked, and the model learns to predict these masked words using the surrounding context.\n",
        "  - Processes text bidirectionally, considering context from both left and right.\n",
        "\n",
        "**3. Contextual Understanding:**\n",
        "- **GPT-2:**\n",
        "  - Focuses on generating coherent and contextually relevant text by leveraging preceding context.\n",
        "- **BERT:**\n",
        "  - Excels in understanding the meaning of words and sentences by analyzing the full context, both preceding and succeeding words.\n",
        "\n",
        "**4. Applications:**\n",
        "- **GPT-2:**\n",
        "  - Well-suited for natural language generation tasks, such as text completion, summarization, and creative writing.\n",
        "- **BERT:**\n",
        "  - Ideal for natural language understanding tasks, including sentiment analysis, named entity recognition, and question answering.\n",
        "\n",
        "**5. Training Data:**\n",
        "- **GPT-2:**\n",
        "  - Trained on a vast, unfiltered corpus of internet text, encompassing diverse content types.\n",
        "- **BERT:**\n",
        "  - Trained on a combination of Wikipedia and BookCorpus, focusing on high-quality text sources.\n",
        "\n",
        "# 6) Why is the Transformer model considered more efficient than RNNs and LSTMs?\n",
        "**Ans:** The Transformer model is considered more efficient than Recurrent Neural Networks (RNNs) and Long Short-Term Memory networks (LSTMs) due to several key factors:\n",
        "\n",
        "**1. Parallel Processing Capability:**\n",
        "- **Transformers:** Utilize a self-attention mechanism that allows for the simultaneous processing of all input elements. This parallelism leads to significantly faster training and inference times, especially with large datasets.\n",
        "- **RNNs and LSTMs:** Process input sequences sequentially, where each step depends on the previous one. This inherent sequential nature limits opportunities for parallel computation, resulting in slower processing times.\n",
        "\n",
        "**2. Effective Handling of Long-Range Dependencies:**\n",
        "- **Transformers:** Employ self-attention mechanisms to capture relationships between distant elements in a sequence efficiently. This design enables them to model long-range dependencies without difficulty.\n",
        "- **RNNs and LSTMs:** While capable of managing long-term dependencies to some extent, they often encounter challenges such as the vanishing gradient problem, which can impede learning over long sequences.\n",
        "\n",
        "**3. Scalability and Model Capacity:**\n",
        "- **Transformers:** Their architecture supports scaling to larger models with increased parameters, enhancing their ability to learn complex patterns from extensive datasets.\n",
        "- **RNNs and LSTMs:** Scaling these models can be more challenging due to training instabilities and the sequential nature of their computations.\n",
        "\n",
        "**4. Memory Efficiency:**\n",
        "- **Transformers:** By processing inputs in parallel and utilizing self-attention, they can be more memory-efficient, especially when dealing with long sequences.\n",
        "- **RNNs and LSTMs:** Maintaining hidden states over long sequences can lead to higher memory consumption and potential inefficiencies.\n",
        "\n",
        "These advantages make Transformers a preferred choice for many natural language processing tasks, leading to their widespread adoption in models like BERT and GPT.\n",
        "\n",
        "# 7) Explain how the attention mechanism works in a Transformer model?\n",
        "**Ans:** In Transformer models, the **attention mechanism** enables the model to weigh the significance of different words in an input sequence when processing each word. This mechanism is pivotal for capturing dependencies and relationships within the data, facilitating more effective learning and generation.\n",
        "\n",
        "**How the Attention Mechanism Works:**\n",
        "\n",
        "1. **Input Representation:**\n",
        "   - Each word in the input sequence is transformed into three vectors:\n",
        "     - **Query (Q):** Determines which words to focus on.\n",
        "     - **Key (K):** Represents the words in the sequence.\n",
        "     - **Value (V):** Contains the actual information of the words.\n",
        "\n",
        "2. **Calculating Attention Scores:**\n",
        "   - The model computes a score for each pair of words by taking the dot product of their Query and Key vectors.\n",
        "   - These scores indicate the relevance of one word to another.\n",
        "\n",
        "3. **Applying Softmax:**\n",
        "   - The scores are passed through a softmax function to convert them into probabilities, emphasizing the most relevant words while diminishing the less relevant ones.\n",
        "\n",
        "4. **Weighted Sum of Values:**\n",
        "   - Each Value vector is weighted by the corresponding softmax probability.\n",
        "   - The model computes a weighted sum of these Value vectors, producing an output that reflects the importance of each word in the context of the input sequence.\n",
        "\n",
        "5. **Multi-Head Attention:**\n",
        "   - The Transformer employs multiple attention mechanisms, known as heads, to capture different aspects of relationships between words.\n",
        "   - Each head processes the input independently, and their outputs are concatenated and linearly transformed to produce the final result.\n",
        "\n",
        "# 8) What is the difference between an encoder and a decoder in a Seq2Seq model?\n",
        "**Ans:** In a Sequence-to-Sequence (Seq2Seq) model, the **encoder** and **decoder** serve distinct yet complementary roles in transforming an input sequence into an output sequence.\n",
        "\n",
        "**Encoder:**\n",
        "\n",
        "- **Function:** Processes the input sequence to capture its essential information and represent it in a fixed-size context vector.\n",
        "\n",
        "- **Operation:** Sequentially reads each element of the input, updating its internal state to encapsulate the sequence's context.\n",
        "\n",
        "- **Output:** Generates a context vector that summarizes the input sequence's information.\n",
        "\n",
        "**Decoder:**\n",
        "\n",
        "- **Function:** Generates the output sequence by interpreting the context vector provided by the encoder.\n",
        "\n",
        "- **Operation:** Produces the output sequence element by element, using the context vector and previously generated elements to inform each step.\n",
        "\n",
        "- **Output:** Constructs the final output sequence, such as a translated sentence in another language.\n",
        "\n",
        "# 9) What is the primary purpose of using the self-attention mechanism in transformers?\n",
        "**Ans:** The primary purpose of the self-attention mechanism in Transformer models is to enable the model to evaluate and assign varying levels of importance to different words within a single input sequence. This capability allows the model to capture intricate relationships and dependencies between words, regardless of their positions in the sequence.\n",
        "\n",
        "# 10)  How does the GPT-2 model generate text?\n",
        "**Ans:** GPT-2, or Generative Pre-trained Transformer 2, generates text by predicting the next word in a sequence based on the preceding context. Here's an overview of how this process works:\n",
        "\n",
        "1. **Input Prompt:** The process begins with an initial text prompt provided by the user. This prompt serves as the starting context for the model.\n",
        "\n",
        "2. **Tokenization:** The input text is divided into tokens, which are smaller units like words or subwords. Each token is then converted into a numerical representation that the model can process.\n",
        "\n",
        "3. **Contextual Embedding:** GPT-2 uses its internal parameters to generate embeddings for each token, capturing the contextual meaning based on the input sequence.\n",
        "\n",
        "4. **Next-Word Prediction:** Leveraging the Transformer architecture, GPT-2 analyzes the sequence of tokens and computes probabilities for potential next tokens. It selects the token with the highest probability as the next word in the sequence.\n",
        "\n",
        "5. **Iterative Generation:** The newly generated token is appended to the input sequence, and the model repeats the prediction process to generate subsequent tokens. This iterative approach continues until the model produces a complete text output of the desired length or until it encounters a stopping criterion.\n",
        "\n",
        "# 11) What is the main difference between the encoder-decoder architecture and a simple neural network?\n",
        "**Ans:** The **encoder-decoder architecture** and a **simple neural network** differ primarily in their design and application, especially concerning sequence processing tasks.\n",
        "\n",
        "**Encoder-Decoder Architecture:**\n",
        "\n",
        "- **Structure:** Comprises two main components:\n",
        "  - **Encoder:** Processes the input sequence and converts it into a fixed-length vector representation, capturing the essential information of the input.\n",
        "  - **Decoder:** Takes this vector representation and generates the output sequence, one element at a time.\n",
        "\n",
        "- **Purpose:** Designed for sequence-to-sequence tasks where the input and output may vary in length and structure, such as machine translation, text summarization, and image captioning.\n",
        "\n",
        "- **Functionality:** Effectively handles variable-length input and output sequences by learning a mapping from the input sequence to the output sequence through the intermediate vector representation.\n",
        "\n",
        "**Simple Neural Network:**\n",
        "\n",
        "- **Structure:** Typically consists of an input layer, one or more hidden layers, and an output layer.\n",
        "\n",
        "- **Purpose:** Suited for tasks where the input and output have fixed dimensions, such as image classification or regression problems.\n",
        "\n",
        "- **Functionality:** Processes input data to produce an output without an intermediate representation tailored for sequence processing.\n",
        "\n",
        "# 12) Explain the concept of “fine-tuning” in BERT?\n",
        "**Ans:** Fine-tuning in BERT (Bidirectional Encoder Representations from Transformers) involves adapting a pre-trained BERT model to a specific downstream task by training it further on task-specific labeled data. This process tailors the general language understanding capabilities of BERT to meet the requirements of particular applications, such as text classification, named entity recognition, or question answering.\n",
        "\n",
        "**Key Aspects of Fine-Tuning BERT:**\n",
        "\n",
        "1. **Task-Specific Adaptation:** After BERT's initial pre-training on large text corpora, fine-tuning adjusts its parameters using labeled data pertinent to a specific task, enabling the model to learn task-related patterns and nuances.\n",
        "\n",
        "2. **Architecture Modification:** Typically, fine-tuning involves adding a task-specific layer, such as a classification head, on top of BERT's architecture. This additional layer is trained alongside the pre-trained layers to produce outputs aligned with the desired task.\n",
        "\n",
        "3. **Training Process:** During fine-tuning, the entire model, including both the pre-trained BERT layers and the newly added task-specific layer, is trained on the labeled dataset. This process usually requires only a few epochs, as BERT has already learned general language representations during pre-training.\n",
        "\n",
        "4. **Parameter Adjustment:** Fine-tuning updates BERT's parameters to better fit the specific task, enhancing performance by aligning the model's understanding with the task's unique characteristics.\n",
        "\n",
        "# 13) How does the attention mechanism handle long-range dependencies in sequences?\n",
        "**Ans:** The attention mechanism effectively manages long-range dependencies in sequences by allowing models to evaluate and assign varying levels of importance to different elements, regardless of their positions. This capability is particularly advantageous in natural language processing tasks, where understanding the relationship between distant words is crucial for grasping context and meaning.\n",
        "# 14) What is the core principle behind the Transformer architecture?\n",
        "**Ans:** The Transformer architecture revolutionized natural language processing by introducing a mechanism that allows models to process and generate sequences without relying on traditional recurrent or convolutional structures. The core principle behind this architecture is the self-attention mechanism, which enables the model to evaluate and assign varying levels of importance to different elements within a sequence, regardless of their positions.\n",
        "# 15) What is the role of the \"position encoding\" in a Transformer model?\n",
        "**Ans:** In Transformer models, the **positional encoding** mechanism is essential for incorporating information about the order of tokens in a sequence. Since Transformers process input data in parallel without inherent sequential awareness, positional encodings provide the necessary context regarding the position of each token, enabling the model to interpret the sequence correctly.\n",
        "\n",
        "**Role of Positional Encoding:**\n",
        "\n",
        "- **Sequence Order Awareness:** By adding positional encodings to token embeddings, the model gains information about the position of each token within the sequence, allowing it to distinguish between different orderings of the same set of words.\n",
        "\n",
        "- **Facilitating Attention Mechanisms:** Positional encodings enable the self-attention mechanism to consider the position of tokens when calculating attention scores, which is crucial for tasks that depend on the relative positioning of words.\n",
        "\n",
        "# 16) How do Transformers use multiple layers of attention?\n",
        "**Ans:** In Transformer models, multiple layers of attention are employed to progressively extract and refine features from input sequences, enhancing the model's ability to capture complex patterns and relationships. This layered approach enables the model to build hierarchical representations, with each layer learning increasingly abstract features.\n",
        "# 17) What does it mean when a model is described as “autoregressive” like GPT-2?\n",
        "**Ans:**\n",
        "An autoregressive model predicts the next element in a sequence by relying on preceding elements. In the context of language models like GPT-2, this means generating text one token at a time, with each token's prediction based on all previously generated tokens.\n",
        "# 18) How does BERT's bidirectional training improve its performance?\n",
        "**Ans:** BERT (Bidirectional Encoder Representations from Transformers) enhances its performance through bidirectional training, enabling it to grasp the context of a word by considering both its preceding and succeeding words. This comprehensive understanding allows BERT to capture intricate language nuances, leading to improved accuracy in various natural language processing tasks.\n",
        "\n",
        "# 19) What are the advantages of using the Transformer over RNN-based models in NLP?\n",
        "**Ans:** Transformers offer several advantages over Recurrent Neural Network (RNN)-based models in Natural Language Processing (NLP):\n",
        "\n",
        "1. **Parallelization**: Unlike RNNs, which process input sequences sequentially, Transformers handle entire sequences simultaneously. This parallel processing significantly reduces training times and allows for more efficient utilization of computational resources.\n",
        "\n",
        "2. **Long-Range Dependency Handling**: Transformers effectively capture long-range dependencies within text due to their self-attention mechanism. This capability enables them to model relationships between distant words without the vanishing gradient issues that RNNs often face.\n",
        "\n",
        "3. **Scalability**: The architecture of Transformers facilitates scaling to larger datasets and models, leading to improved performance across various NLP tasks. This scalability has been instrumental in the development of large language models like GPT and BERT.\n",
        "\n",
        "4. **Reduced Training Time**: Due to their parallel processing capabilities, Transformers require less training time compared to RNNs, making them more efficient for large-scale language modeling.\n",
        "\n",
        "5. **Enhanced Performance**: Transformers have consistently outperformed RNNs in various NLP tasks, including language comprehension, text translation, and context capturing, making them the preferred choice for many applications.\n",
        "\n",
        "# 20) What is the attention mechanism’s impact on the performance of models like BERT and GPT-2?\n",
        "**Ans:** The attention mechanism is a pivotal component in models like BERT and GPT-2, significantly enhancing their performance in natural language processing tasks. Its impact can be understood through several key aspects:\n",
        "\n",
        "1. **Contextual Understanding**: Attention allows these models to weigh the importance of different words in a sentence, enabling a nuanced grasp of context. This capability is crucial for tasks such as machine translation and sentiment analysis, where understanding the relationship between words is essential.\n",
        "\n",
        "2. **Handling Long-Range Dependencies**: Traditional models often struggle with capturing relationships between distant words. The attention mechanism addresses this by enabling models to consider the relevance of all words in a sequence, regardless of their position, thereby effectively managing long-range dependencies.\n",
        "\n",
        "3. **Parallelization and Efficiency**: Incorporating attention mechanisms allows models to process input sequences in parallel, rather than sequentially. This parallelization leads to more efficient computation and faster training times, which is particularly beneficial when dealing with large datasets.\n",
        "\n",
        "4. **Interpretability**: The attention mechanism provides insights into the decision-making process of models like BERT and GPT-2. By visualizing attention weights, researchers can understand which parts of the input the model focuses on, enhancing interpretability and trust in model predictions.\n",
        "\n",
        "5. **Scalability**: The modular nature of attention mechanisms facilitates the scaling of models to handle more complex tasks and larger datasets, contributing to the development of advanced language models with superior performance.\n"
      ],
      "metadata": {
        "id": "Qk3Wx6ll9VIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical\n"
      ],
      "metadata": {
        "id": "By7wi1gkNwZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) How to implement a simple text classification model using LSTM in Keras?"
      ],
      "metadata": {
        "id": "rPLJUj0gVQyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "texts = [\n",
        "    'Sample text data for classification',\n",
        "    'Another text for classification',\n",
        "    'More text data here',\n",
        "    'This is a different text',\n",
        "    'And another sample text'\n",
        "]\n",
        "labels = [0, 1, 0, 1, 0]  # Replace with your labels\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 5000\n",
        "max_len = 100\n",
        "embedding_dim = 100\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model building\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
        "    LSTM(128, activation='relu', return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(4, activation='softmax')  # Adjust the output units and activation based on your number of classes\n",
        "])\n",
        "\n",
        "# Model compilation\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "# Convert X_train and y_train to NumPy arrays with dtype=float32\n",
        "X_train = np.array(X_train, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=np.float32)\n",
        "X_val = np.array(X_val, dtype=np.float32)\n",
        "y_val = np.array(y_val, dtype=np.float32)\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n"
      ],
      "metadata": {
        "id": "fMxWAltnVkOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) How to generate sequences of text using a Recurrent Neural Network (RNN)?"
      ],
      "metadata": {
        "id": "MfWWA5ugVlD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "text = \"Your text data here\"\n",
        "vocab = sorted(set(text))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
        "idx_to_char = np.array(vocab)\n",
        "\n",
        "# Convert text to integer sequences\n",
        "text_as_int = np.array([char_to_idx[c] for c in text])\n",
        "\n",
        "# Create input-output pairs\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text) - seq_length\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Build the model\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, batch_input_shape=[BATCH_SIZE, None]),\n",
        "    LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "    Dense(vocab_size)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 10\n",
        "history = model.fit(dataset, epochs=EPOCHS)\n",
        "\n",
        "# Text generation function\n",
        "def generate_text(model, start_string, num_generate=1000):\n",
        "    input_eval = [char_to_idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "\n",
        "    temperature = 1.0\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(idx_to_char[predicted_id])\n",
        "\n",
        "    return start_string + ''.join(text_generated)\n",
        "\n",
        "# Generate text\n",
        "print(generate_text(model, start_string=\"Once upon a time\"))\n"
      ],
      "metadata": {
        "id": "jErEwg5VVqFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) How to perform sentiment analysis using a simple CNN model?"
      ],
      "metadata": {
        "id": "tjh1g3rWXeWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample data\n",
        "texts = ['I love this movie', 'I hate this movie']  # Replace with your dataset\n",
        "labels = [1, 0]  # 1 for positive, 0 for negative\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 5000\n",
        "max_len = 100\n",
        "embedding_dim = 100\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model building\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Model compilation\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "# Convert X_train and y_train to NumPy arrays with dtype=float32\n",
        "X_train = np.array(X_train, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=np.float32)\n",
        "X_val = np.array(X_val, dtype=np.float32)\n",
        "y_val = np.array(y_val, dtype=np.float32)\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n"
      ],
      "metadata": {
        "id": "gb6OOVX3XiAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) How to perform Named Entity Recognition (NER) using spaCy?"
      ],
      "metadata": {
        "id": "iBEOrKIIXzIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "9T7txFuTYW8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the pre-trained model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over the identified entities\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "YVDOw3yuYiKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) How to implement a simple Seq2Seq model for machine translation using LSTM in Keras?"
      ],
      "metadata": {
        "id": "YTgiG_HIYt1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Sample data\n",
        "source_texts = ['Hello', 'How are you?']  # Replace with your dataset\n",
        "target_texts = ['Bonjour', 'Comment ça va?']  # Replace with your dataset\n",
        "\n",
        "# Tokenization and sequence conversion\n",
        "source_tokenizer = Tokenizer()\n",
        "target_tokenizer = Tokenizer()\n",
        "source_tokenizer.fit_on_texts(source_texts)\n",
        "target_tokenizer.fit_on_texts(target_texts)\n",
        "\n",
        "source_sequences = source_tokenizer.texts_to_sequences(source_texts)\n",
        "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "# Padding sequences\n",
        "max_source_len = max(len(seq) for seq in source_sequences)\n",
        "max_target_len = max(len(seq) for seq in target_sequences)\n",
        "source_sequences = pad_sequences(source_sequences, maxlen=max_source_len, padding='post')\n",
        "target_sequences = pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n",
        "\n",
        "# Vocabulary sizes\n",
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 256\n",
        "latent_dim = 512\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(source_vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb = Embedding(target_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Seq2Seq Model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Data preparation for training\n",
        "# Convert target sequences to one-hot encoded format\n",
        "def one_hot_encode(sequences, vocab_size):\n",
        "    one_hot = np.zeros((len(sequences), max_target_len, vocab_size), dtype='float32')\n",
        "    for i, seq in enumerate(sequences):\n",
        "        for t, word_id in enumerate(seq):\n",
        "            if word_id > 0:\n",
        "                one_hot[i, t, word_id] = 1.0\n",
        "    return one_hot\n",
        "\n",
        "target_sequences_one_hot = one_hot_encode(target_sequences, target_vocab_size)\n",
        "\n",
        "# Training\n",
        "model.fit([source_sequences, target_sequences], target_sequences_one_hot,\n",
        "          batch_size=64, epochs=100, validation_split=0.2)\n",
        "\n",
        "# Inference models\n",
        "# Encoder inference model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder inference model\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2 = Embedding(target_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
        "    dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "# Function to decode sequences\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_tokenizer.word_index['\\t']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = target_tokenizer.index_word[sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_word\n",
        "\n",
        "        # Exit condition: either hit max length or find stop character.\n",
        "        if sampled_word == '\\n' or len(decoded_sentence) > max_target_len:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "xr_EzsHkY2P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) How to generate text using a pre-trained transformer model (GPT-2)?"
      ],
      "metadata": {
        "id": "j49DIZblZSU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "VdDPEYpBZ8DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model_name = 'gpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "prompt = \"Once upon a time\"\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, early_stopping=True)\n",
        "\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504,
          "referenced_widgets": [
            "7ba4501990064af099751cffef002de5",
            "3cb27bee4b984c469d25de1f2cf6d352",
            "f732b89e2de546d2bc7e95f8a68fcd26",
            "e6a8fd127c6f4d3eac3596a46a84a038",
            "fbf9976e4fee49f096e1c7c8b4dd6e86",
            "e1a0a74887d349e594ab69d57aa31ad0",
            "a2a75ff077904aa18614cafa4c98586d",
            "bf29254081c94c4f9fa2aa4ffccb6164",
            "442dd1814fa549c2a023e1f720d4820a",
            "b59db2866d6b44a4b726d7c220901b0f",
            "a3fedbc566794e599ebf1ead0053239b",
            "139d167d4b5249198d090efbc0a6c78a",
            "5ac9390c53974f61990c515760e3f725",
            "cfbd5868c5d14b1683a6507813d74d42",
            "31072a56d8274af693a25014fce381d0",
            "a3dddb26066047a0b5d24c706d581d41",
            "a150c4165c4c41e29195205b9cc246f6",
            "158bd2f13b4f433dafe6642ae0b0e165",
            "bff0a7eb929046b795921cc935cf4ea3",
            "7e7f23d24844424d87c6213011a988af",
            "465c6d0c9ce047c2ab35cb2b731a9d41",
            "6f853a5c47614ca5953b9752737d7bc0",
            "140e4b8633704bc1bd9c536f2b6cd4ed",
            "55c05fe7be16499c8c43ac05e71d73d6",
            "5ec61bc0da0d4e6998ef8fbfafdb9a87",
            "fec7c11f573a4a22b252962e03eaf79a",
            "cc5508b9d47244278e71706fa8e9e4b5",
            "0f20bba50ef449dd99ec6931680e33a7",
            "19a5fa7b26f548c8951f0f42bad4b3cb",
            "50a08730326b4bc2918feb2207bc0662",
            "b7bc809488054f31a21a03399f8ec095",
            "b277ae299ec34bec89d586c4348fe824",
            "2daeff5b8f314acea06b1392590b5063",
            "61fc53a26ae047dd861265285bead44b",
            "20fc9917d9014851ba600db60564b39b",
            "7a63d7f3f3b24f1f8826f7983d7413c6",
            "55380c1709b3461ea9c66df50a12be54",
            "a14d86c78df7450c8a17e9c694853c69",
            "8ece2c2889e94314832c240569864bad",
            "a965471315604bd8a8d3d819b74c507d",
            "22d69805b51f475da40384bdb605a60c",
            "627faac3cd0944ccad5e7d0270ecd5ee",
            "bd1c6adf39a24aa89dfbb59db2259e44",
            "192aaa4f0008479fbcabdfb03734e5fb",
            "5e12a61cddc34071813c79d723d370aa",
            "ab72e140b62c43159803bccffda22116",
            "d88765d4bc5a4d14a1f938e7c8ca7941",
            "c3ba7c9131bb46748710fc65f5ca42e4",
            "758a56834f384ee49555ab95c615aa01",
            "294a39856aeb46cbbef1d360dc561a28",
            "116e70f80eb84537b6d0335469b2d986",
            "aab493ee8f6d4f22a9817ffa133d8885",
            "ef659fe1117842fbbf95785758f9e21d",
            "3f548420a1f840e5a1dd2840d110fd16",
            "65761d782fd54c49882a50f0c47c664d",
            "a625525cfd734820a98ae15569dab0f5",
            "56aa4009fc8542f5a093e554b84ff4de",
            "626ea821438048c385aa67a6a0c20c89",
            "647527b05ecc42ffb869b182ba464f51",
            "a945e873ee5e4c9281d1858eeefcd509",
            "a7e6988e99c9425ca6d1d842b6a16eba",
            "6b4f595fde514badb859226110c6f2c7",
            "dd4158715f5f48bc80d6c5ed93875868",
            "7cc49c0d7373488e9b774a44cda4a35b",
            "40fb04d47e6c4d54b0f726a64708e851",
            "1e7f75502bc34415ac61ca6be063bd23",
            "66108bdd54704cb79ac14e7f329e9a69",
            "a6913ce535924185bd8fc5c45db84434",
            "fbfa4d6274364d6785dbed67445d5bfd",
            "2281d388aa48486482a7c64948184418",
            "1f37a97e74a44475a19076832961c740",
            "80c36e5582f3446cb8de4c41e1f5b400",
            "029158e74b1c4ac5b2402a9d569ca778",
            "19b232d5aa4b4d9499aede19808813ff",
            "b4b5f2f8eb274a828e7628a3ee9f75e5",
            "a8ddb2cbc1eb49cabead02146c5574ad",
            "ee46bdfce576444e8b44367d059ffbf2"
          ]
        },
        "id": "bkHEDW2laK2h",
        "outputId": "3301e6dd-88df-4457-da78-f1dff63a934a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ba4501990064af099751cffef002de5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "139d167d4b5249198d090efbc0a6c78a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "140e4b8633704bc1bd9c536f2b6cd4ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61fc53a26ae047dd861265285bead44b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e12a61cddc34071813c79d723d370aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a625525cfd734820a98ae15569dab0f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66108bdd54704cb79ac14e7f329e9a69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, the world was a place of great beauty and great danger. The world of the gods was the place where the great gods were born, and where they were to live.\n",
            "\n",
            "The world that was created was not the same as the one that is now. It was an endless, endless world. And the Gods were not born of nothing. They were created of a single, single thing. That was why the universe was so beautiful. Because the cosmos was made of two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) How to apply data augmentation for text in NLP?"
      ],
      "metadata": {
        "id": "bW2LBwznab9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textattack"
      ],
      "metadata": {
        "id": "-xWrjLrxbDvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textattack.augmentation import EasyDataAugmenter\n",
        "\n",
        "# Initialize the augmenter\n",
        "augmenter = EasyDataAugmenter()\n",
        "\n",
        "# Original sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Generate augmented sentences\n",
        "augmented_sentences = augmenter.augment(sentence)\n",
        "\n",
        "print(augmented_sentences)\n"
      ],
      "metadata": {
        "id": "m1gTVi-ual4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) How can you add an Attention Mechanism to a Seq2Seq model?"
      ],
      "metadata": {
        "id": "5qI3nzn0a6Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer, Input, LSTM, Dense, Concatenate, TimeDistributed\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[0][-1], input_shape[0][-1]), initializer='normal', name='W')\n",
        "        self.b = self.add_weight(shape=(input_shape[0][-1],), initializer='zeros', name='b')\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        encoder_out, decoder_out = inputs\n",
        "        score = K.tanh(K.dot(decoder_out, self.W) + self.b)\n",
        "        attention_weights = K.softmax(K.dot(score, K.transpose(encoder_out), axes=[1, 2]))\n",
        "        context_vector = K.batch_dot(attention_weights, encoder_out, axes=[1, 1])\n",
        "        return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "HOuRHLjPbYAV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_dim, output_dim, timesteps, latent_dim):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(timesteps, input_dim))\n",
        "    encoder_lstm = LSTM(latent_dim, return_sequences=True)(encoder_inputs)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(timesteps, output_dim))\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True)(decoder_inputs)\n",
        "\n",
        "    # Attention\n",
        "    attention = Attention()([encoder_lstm, decoder_lstm])\n",
        "    context_vector = attention[0]\n",
        "    attention_weights = attention[1]\n",
        "\n",
        "    # Concatenate context vector with decoder LSTM output\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_lstm])\n",
        "\n",
        "    # Output layer\n",
        "    decoder_dense = TimeDistributed(Dense(output_dim, activation='softmax'))\n",
        "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "VZ572NRdbh_7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train and Y_train are your training data\n",
        "model = build_model(input_dim=X_train.shape[2], output_dim=Y_train.shape[2], timesteps=X_train.shape[1], latent_dim=256)\n",
        "model.fit([X_train, Y_train], Y_train, epochs=10, batch_size=64)\n"
      ],
      "metadata": {
        "id": "SI6_ccKAbmGG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}